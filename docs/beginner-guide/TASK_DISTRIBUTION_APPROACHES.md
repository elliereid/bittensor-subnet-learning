# ğŸ“¡ Task Distribution Approaches in Bittensor Subnets

Complete explanation of different ways to send tasks to miners in a subnet, their pros/cons, and when to use each.

## ğŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Approach 1: Standard Bittensor Synapse](#approach-1-standard-bittensor-synapse)
3. [Approach 2: External API/WebSocket](#approach-2-external-apiwebsocket)
4. [Approach 3: On-Chain Task Storage](#approach-3-on-chain-task-storage)
5. [Approach 4: IPFS/Decentralized Storage](#approach-4-ipfsdecentralized-storage)
6. [Approach 5: Pub/Sub Message Queues](#approach-5-pubsub-message-queues)
7. [Approach 6: Direct HTTP Endpoints](#approach-6-direct-http-endpoints)
8. [Approach 7: Event-Driven Architecture](#approach-7-event-driven-architecture)
9. [Hybrid Approaches](#hybrid-approaches)
10. [Comparison Table](#comparison-table)

---

## ğŸ¯ Overview

There are multiple ways to distribute tasks to miners in a Bittensor subnet. Each has different trade-offs:

```
Task Distribution Methods:

1. Standard Synapse (Validator â†’ Miner)
   â””â”€â–º Direct query-response pattern

2. External API/WebSocket
   â””â”€â–º External system pushes tasks

3. On-Chain Storage
   â””â”€â–º Tasks stored on blockchain

4. IPFS/Decentralized Storage
   â””â”€â–º Tasks in distributed storage

5. Pub/Sub Queues
   â””â”€â–º Message broker system

6. Direct HTTP
   â””â”€â–º Miners expose APIs

7. Event-Driven
   â””â”€â–º Events trigger tasks
```

---

## ğŸ”„ Approach 1: Standard Bittensor Synapse

### How It Works

**Flow**:
```
Validator â†’ Creates Synapse â†’ Queries Miner â†’ Miner Processes â†’ Returns Response
```

**Characteristics**:
- Validator initiates all requests
- Synchronous request-response pattern
- Tasks are created by validators on-demand
- No external systems needed

### Implementation

**Validator Side** (`template/validator/forward.py`):
```python
async def forward(self):
    # Validator creates task
    synapse = Dummy(dummy_input=5)
    
    # Validator queries miner
    response = await self.dendrite(
        axons=[miner_axon],
        synapse=synapse,
        deserialize=True
    )
    
    # Validator scores response
    reward = score(response)
```

**Miner Side** (`neurons/miner.py`):
```python
async def forward(self, synapse: Dummy) -> Dummy:
    # Miner receives task from validator
    # Process immediately
    synapse.dummy_output = synapse.dummy_input * 2
    return synapse
```

### Pros âœ…
- âœ… Fully decentralized (no external dependencies)
- âœ… Built into Bittensor (no extra infrastructure)
- âœ… Validator controls task distribution
- âœ… Simple to implement
- âœ… Works out of the box

### Cons âŒ
- âŒ Validator must know what to query
- âŒ No persistent task queue
- âŒ Tasks are ephemeral (lost if miner offline)
- âŒ Limited to validator-initiated tasks
- âŒ Can't handle external events

### Use Cases
- âœ… Simple query-response subnets
- âœ… On-demand computation
- âœ… When validators generate tasks
- âœ… Testing and development

### Examples
- **Subnet 1 (Prompting)**: Validator sends prompts, miner generates responses
- **Template subnet**: Dummy multiplication tasks

---

## ğŸŒ Approach 2: External API/WebSocket

### How It Works

**Flow**:
```
External System â†’ API/WebSocket â†’ Miner â†’ Processes Task â†’ Stores Result
                                                                    â†“
Validator â†’ Queries Miner â†’ Gets Stored Results â†’ Scores
```

**Characteristics**:
- External system (outside Bittensor) sends tasks
- Miners receive tasks independently of validators
- Tasks are persistent (stored until processed)
- Validators query miners for completed tasks

### Implementation

**External System**:
```python
# External API/WebSocket server
websocket.send({
    "task_id": "123",
    "task_type": "image_classification",
    "data": {"image_url": "https://..."}
})
```

**Miner Side** (`neurons/miner.py`):
```python
class Miner(BaseMinerNeuron):
    def __init__(self):
        # Connect to external WebSocket
        self.ws = WebSocketClient("wss://api.example.com")
        self.ws.on_message = self.handle_task
        self.task_storage = {}
    
    def handle_task(self, message):
        # Receive task from external system
        task = json.loads(message)
        result = self.process_task(task)
        self.task_storage[task['id']] = result
    
    async def forward(self, synapse: TaskQuerySynapse):
        # Validator queries for stored results
        return self.task_storage.get(synapse.task_id)
```

**Validator Side** (`template/validator/forward.py`):
```python
async def forward(self):
    # Query miners for their stored task results
    responses = await self.dendrite(
        axons=[...],
        synapse=TaskQuerySynapse(task_id=None),  # Get all recent
        deserialize=True
    )
    
    # Score based on stored results
    rewards = score_stored_tasks(responses)
```

### Pros âœ…
- âœ… External systems can push tasks
- âœ… Tasks persist until processed
- âœ… Decouples task creation from validation
- âœ… Can handle real-time events
- âœ… Supports high-frequency tasks

### Cons âŒ
- âŒ Requires external infrastructure
- âŒ Centralized point of failure (API/WebSocket server)
- âŒ Additional complexity
- âŒ Need to manage external systems

### Use Cases
- âœ… Order processing (like TensorUSD)
- âœ… Real-time data processing
- âœ… External event-driven tasks
- âœ… High-frequency task distribution

### Examples
- **TensorUSD Subnet**: External gateway sends buy/sell orders via WebSocket
- **Trading subnets**: External trading signals

---

## â›“ï¸ Approach 3: On-Chain Task Storage

### How It Works

**Flow**:
```
Task Creator â†’ Stores Task on Blockchain â†’ Miners Read Chain â†’ Process Task
                                                                    â†“
Validator â†’ Queries Miner â†’ Gets Results â†’ Scores
```

**Characteristics**:
- Tasks stored as on-chain data
- Fully decentralized (no external servers)
- Miners read blockchain for tasks
- Tasks are permanent and verifiable

### Implementation

**Task Storage** (On-chain):
```python
# Store task on-chain (using Bittensor's storage or custom pallet)
task_data = {
    "task_id": "123",
    "task_type": "compute",
    "input_data": "...",
    "reward": 100  # TAO reward for completion
}

# Store in on-chain storage
subtensor.set_storage(netuid=1, key="task_123", value=task_data)
```

**Miner Side** (`neurons/miner.py`):
```python
class Miner(BaseMinerNeuron):
    def __init__(self):
        self.processed_tasks = set()
    
    def run(self):
        while True:
            # Read tasks from chain
            tasks = self.subtensor.get_storage(netuid=1, prefix="task_")
            
            for task_id, task_data in tasks.items():
                if task_id not in self.processed_tasks:
                    result = self.process_task(task_data)
                    self.processed_tasks.add(task_id)
                    
                    # Store result on-chain
                    self.subtensor.set_storage(
                        netuid=1,
                        key=f"result_{task_id}",
                        value=result
                    )
```

**Validator Side** (`template/validator/forward.py`):
```python
async def forward(self):
    # Read task results from chain
    for miner_uid in miner_uids:
        results = self.subtensor.get_storage(
            netuid=1,
            prefix=f"result_{miner_uid}_"
        )
        rewards[uid] = score_results(results)
```

### Pros âœ…
- âœ… Fully decentralized
- âœ… Tasks are permanent and verifiable
- âœ… No external infrastructure needed
- âœ… Transparent and auditable
- âœ… Tasks can't be lost

### Cons âŒ
- âŒ On-chain storage is expensive
- âŒ Limited storage capacity
- âŒ Slower (blockchain confirmation time)
- âŒ Not suitable for high-frequency tasks
- âŒ Requires custom storage pallet

### Use Cases
- âœ… Important, permanent tasks
- âœ… When transparency is critical
- âœ… Low-frequency, high-value tasks
- âœ… Decentralized task markets

### Examples
- **Decentralized compute markets**: Tasks stored on-chain
- **Permanent data processing**: Historical data analysis

---

## ğŸ“¦ Approach 4: IPFS/Decentralized Storage

### How It Works

**Flow**:
```
Task Creator â†’ Uploads Task to IPFS â†’ Gets CID â†’ Stores CID on-chain/API
                                                                    â†“
Miner â†’ Reads CID â†’ Fetches from IPFS â†’ Processes Task
                                                                    â†“
Miner â†’ Uploads Result to IPFS â†’ Stores Result CID
                                                                    â†“
Validator â†’ Queries Miner â†’ Gets Result CID â†’ Fetches from IPFS â†’ Scores
```

**Characteristics**:
- Tasks stored in IPFS (decentralized file storage)
- Only CID (Content Identifier) stored on-chain
- Large tasks/data supported
- Decentralized storage

### Implementation

**Task Creation**:
```python
import ipfshttpclient

# Create task
task = {
    "task_id": "123",
    "task_type": "image_processing",
    "image_data": large_image_bytes
}

# Upload to IPFS
ipfs = ipfshttpclient.connect()
cid = ipfs.add_json(task)  # Returns CID like "QmXxx..."

# Store CID (on-chain or API)
store_cid("task_123", cid)
```

**Miner Side** (`neurons/miner.py`):
```python
class Miner(BaseMinerNeuron):
    def __init__(self):
        self.ipfs = ipfshttpclient.connect()
        self.processed_cids = set()
    
    def run(self):
        while True:
            # Get task CIDs (from chain or API)
            task_cids = get_pending_task_cids()
            
            for cid in task_cids:
                if cid not in self.processed_cids:
                    # Fetch task from IPFS
                    task = self.ipfs.get_json(cid)
                    
                    # Process task
                    result = self.process_task(task)
                    
                    # Upload result to IPFS
                    result_cid = self.ipfs.add_json(result)
                    self.store_result_cid(task['task_id'], result_cid)
                    self.processed_cids.add(cid)
```

**Validator Side** (`template/validator/forward.py`):
```python
async def forward(self):
    # Query miners for result CIDs
    responses = await self.dendrite(
        axons=[...],
        synapse=ResultCIDQuerySynapse(),
        deserialize=True
    )
    
    # Fetch results from IPFS and score
    for response in responses:
        result = ipfs.get_json(response.result_cid)
        score = evaluate_result(result)
```

### Pros âœ…
- âœ… Supports large files/data
- âœ… Decentralized storage
- âœ… Cost-effective (IPFS is free)
- âœ… Permanent storage (if pinned)
- âœ… Can store complex data structures

### Cons âŒ
- âŒ Requires IPFS infrastructure
- âŒ Slower than direct storage
- âŒ Need to manage pinning
- âŒ CID management complexity
- âŒ Retrieval can be slow

### Use Cases
- âœ… Large file processing (images, videos)
- âœ… Dataset processing
- âœ… When storage cost matters
- âœ… Decentralized data processing

### Examples
- **Image processing subnets**: Large images in IPFS
- **Dataset analysis**: Datasets stored in IPFS

---

## ğŸ“¨ Approach 5: Pub/Sub Message Queues

### How It Works

**Flow**:
```
Task Creator â†’ Publishes to Queue (Redis/RabbitMQ) â†’ Miners Subscribe
                                                                    â†“
Miner â†’ Receives Task â†’ Processes â†’ Publishes Result
                                                                    â†“
Validator â†’ Subscribes to Results â†’ Scores
```

**Characteristics**:
- Message broker (Redis, RabbitMQ, Kafka)
- Pub/Sub pattern
- Tasks queued until consumed
- Supports multiple subscribers

### Implementation

**Using Redis Pub/Sub**:

**Task Publisher**:
```python
import redis

redis_client = redis.Redis()

# Publish task
task = {"task_id": "123", "data": "..."}
redis_client.publish("subnet_tasks", json.dumps(task))
```

**Miner Side** (`neurons/miner.py`):
```python
import redis

class Miner(BaseMinerNeuron):
    def __init__(self):
        self.redis = redis.Redis()
        self.pubsub = self.redis.pubsub()
        self.pubsub.subscribe("subnet_tasks")
        self.task_results = {}
    
    def run(self):
        # Listen for tasks
        for message in self.pubsub.listen():
            if message['type'] == 'message':
                task = json.loads(message['data'])
                result = self.process_task(task)
                
                # Publish result
                self.redis.publish(
                    f"subnet_results_{self.uid}",
                    json.dumps(result)
                )
```

**Validator Side** (`template/validator/forward.py`):
```python
async def forward(self):
    # Subscribe to miner result channels
    for uid in miner_uids:
        results = redis_client.pubsub()
        results.subscribe(f"subnet_results_{uid}")
        
        # Collect results
        task_results[uid] = collect_recent_results(results)
    
    # Score results
    rewards = score_results(task_results)
```

### Pros âœ…
- âœ… Real-time task distribution
- âœ… Scalable (handles many miners)
- âœ… Reliable (message persistence)
- âœ… Supports priority queues
- âœ… Decouples producers/consumers

### Cons âŒ
- âŒ Requires message broker infrastructure
- âŒ Centralized broker (unless using decentralized queue)
- âŒ Additional complexity
- âŒ Need to manage broker

### Use Cases
- âœ… High-frequency tasks
- âœ… Real-time processing
- âœ… When you need message persistence
- âœ… Microservices architecture

### Examples
- **Real-time data processing**: Stock prices, sensor data
- **Event-driven subnets**: IoT data processing

---

## ğŸŒ Approach 6: Direct HTTP Endpoints

### How It Works

**Flow**:
```
Task Creator â†’ HTTP POST to Miner â†’ Miner Processes â†’ Returns Response
                                                                    â†“
Validator â†’ HTTP GET from Miner â†’ Gets Results â†’ Scores
```

**Characteristics**:
- Miners expose HTTP REST APIs
- Direct HTTP communication
- Standard web protocols
- Can be called by anyone

### Implementation

**Miner Side** (`neurons/miner.py`):
```python
from flask import Flask, request, jsonify

class Miner(BaseMinerNeuron):
    def __init__(self):
        super().__init__()
        self.app = Flask(__name__)
        self.setup_routes()
        self.task_results = {}
    
    def setup_routes(self):
        @self.app.route('/task', methods=['POST'])
        def receive_task():
            task = request.json
            result = self.process_task(task)
            self.task_results[task['id']] = result
            return jsonify(result)
        
        @self.app.route('/results/<task_id>', methods=['GET'])
        def get_result(task_id):
            return jsonify(self.task_results.get(task_id))
    
    def run(self):
        # Run HTTP server
        self.app.run(host='0.0.0.0', port=8091)
```

**Task Creator**:
```python
import requests

# Send task to miner
response = requests.post(
    f"http://{miner_ip}:8091/task",
    json={"task_id": "123", "data": "..."}
)
```

**Validator Side** (`template/validator/forward.py`):
```python
async def forward(self):
    import aiohttp
    
    async with aiohttp.ClientSession() as session:
        for uid in miner_uids:
            miner_ip = self.metagraph.axons[uid].ip
            
            # Query miner via HTTP
            async with session.get(
                f"http://{miner_ip}:8091/results/recent"
            ) as response:
                results = await response.json()
                task_results[uid] = results
    
    rewards = score_results(task_results)
```

### Pros âœ…
- âœ… Standard HTTP (easy integration)
- âœ… Can be called by external systems
- âœ… Simple to implement
- âœ… Works with existing tools
- âœ… RESTful API design

### Cons âŒ
- âŒ Requires HTTP server on miners
- âŒ Not using Bittensor's built-in communication
- âŒ Need to manage HTTP endpoints
- âŒ Less secure (unless adding auth)
- âŒ Bypasses Bittensor's network layer

### Use Cases
- âœ… When external systems need direct access
- âœ… REST API integration
- âœ… Web-based task submission
- âœ… Integration with existing systems

### Examples
- **API-based subnets**: External services call miner APIs
- **Web interfaces**: Users submit tasks via web UI

---

## âš¡ Approach 7: Event-Driven Architecture

### How It Works

**Flow**:
```
Event Source â†’ Event Stream â†’ Miners Subscribe â†’ Process Events
                                                                    â†“
Validator â†’ Queries Event Results â†’ Scores
```

**Characteristics**:
- Events trigger task processing
- Event streaming (Kafka, AWS Kinesis)
- Real-time processing
- Event sourcing pattern

### Implementation

**Event Producer**:
```python
from kafka import KafkaProducer

producer = KafkaProducer()

# Produce event
event = {
    "event_type": "image_uploaded",
    "event_id": "123",
    "data": {"image_url": "https://..."}
}

producer.send("subnet_events", json.dumps(event).encode())
```

**Miner Side** (`neurons/miner.py`):
```python
from kafka import KafkaConsumer

class Miner(BaseMinerNeuron):
    def __init__(self):
        self.consumer = KafkaConsumer(
            "subnet_events",
            group_id=f"miner_{self.uid}"
        )
        self.event_results = {}
    
    def run(self):
        for event in self.consumer:
            event_data = json.loads(event.value)
            
            # Process event as task
            result = self.process_event(event_data)
            self.event_results[event_data['event_id']] = result
```

**Validator Side** (`template/validator/forward.py`):
```python
async def forward(self):
    # Query miners for event processing results
    responses = await self.dendrite(
        axons=[...],
        synapse=EventResultQuerySynapse(),
        deserialize=True
    )
    
    # Score based on event processing
    rewards = score_event_results(responses)
```

### Pros âœ…
- âœ… Real-time event processing
- âœ… Scalable event streaming
- âœ… Decouples event sources from processing
- âœ… Supports complex event patterns
- âœ… Event replay capability

### Cons âŒ
- âŒ Requires event streaming infrastructure
- âŒ Complex setup
- âŒ Need to manage event streams
- âŒ Additional infrastructure cost

### Use Cases
- âœ… Real-time event processing
- âœ… IoT data processing
- âœ… Log analysis
- âœ… Stream processing

### Examples
- **IoT subnets**: Sensor events trigger processing
- **Log analysis**: Log events trigger analysis

---

## ğŸ”€ Hybrid Approaches

### Common Combinations

#### 1. WebSocket + Synapse
```
External System â†’ WebSocket â†’ Miner (stores tasks)
                                    â†“
Validator â†’ Synapse Query â†’ Miner (returns stored results)
```

#### 2. IPFS + On-Chain CIDs
```
Task â†’ IPFS â†’ CID â†’ On-Chain Storage â†’ Miners Read Chain â†’ Fetch IPFS
```

#### 3. API + Pub/Sub
```
API â†’ Publishes to Queue â†’ Miners Subscribe â†’ Process â†’ Results Queue
```

---

## ğŸ“Š Comparison Table

| Approach | Decentralization | Complexity | Speed | Cost | Use Case |
|----------|-----------------|------------|-------|------|----------|
| **Standard Synapse** | âœ…âœ…âœ… High | â­ Low | âš¡âš¡âš¡ Fast | ğŸ’° Low | Simple queries |
| **External API/WS** | âš ï¸ Medium | â­â­ Medium | âš¡âš¡âš¡ Fast | ğŸ’°ğŸ’° Medium | External tasks |
| **On-Chain Storage** | âœ…âœ…âœ… High | â­â­â­ High | âš¡ Slow | ğŸ’°ğŸ’°ğŸ’° High | Permanent tasks |
| **IPFS Storage** | âœ…âœ… Medium | â­â­ Medium | âš¡âš¡ Medium | ğŸ’° Low | Large files |
| **Pub/Sub Queue** | âš ï¸ Low | â­â­â­ High | âš¡âš¡âš¡ Fast | ğŸ’°ğŸ’° Medium | High frequency |
| **HTTP Endpoints** | âš ï¸ Low | â­â­ Medium | âš¡âš¡âš¡ Fast | ğŸ’° Low | External access |
| **Event-Driven** | âš ï¸ Low | â­â­â­ High | âš¡âš¡âš¡ Fast | ğŸ’°ğŸ’°ğŸ’° High | Real-time events |

**Legend**:
- âœ…âœ…âœ… = Fully decentralized
- âœ…âœ… = Mostly decentralized
- âš ï¸ = Centralized component
- â­ = Complexity level (1-3)
- âš¡ = Speed (1-3)
- ğŸ’° = Cost (1-3)

---

## ğŸ¯ Choosing the Right Approach

### Decision Tree

```
Do you need external systems to send tasks?
â”œâ”€ NO â†’ Use Standard Synapse
â””â”€ YES
    â”œâ”€ Do you need real-time?
    â”‚   â”œâ”€ YES â†’ WebSocket or Pub/Sub
    â”‚   â””â”€ NO â†’ API Polling
    â”‚
    â”œâ”€ Do you need large file storage?
    â”‚   â”œâ”€ YES â†’ IPFS
    â”‚   â””â”€ NO â†’ Continue
    â”‚
    â”œâ”€ Do you need full decentralization?
    â”‚   â”œâ”€ YES â†’ On-Chain Storage
    â”‚   â””â”€ NO â†’ API/WebSocket
    â”‚
    â””â”€ Do you need event streaming?
        â”œâ”€ YES â†’ Event-Driven
        â””â”€ NO â†’ Standard API
```

---

## ğŸ’¡ Recommendations

### For Most Subnets
**Start with Standard Synapse** - It's simple and works for most cases.

### For External Integration
**Use WebSocket + Synapse Hybrid** - External system pushes tasks, validators query via synapse.

### For Large Data
**Use IPFS + On-Chain CIDs** - Store data in IPFS, reference on-chain.

### For High Frequency
**Use Pub/Sub Queue** - Handles high-frequency tasks efficiently.

---

**See API_WEBSOCKET_INTEGRATION_GUIDE.md for detailed implementation examples!**

